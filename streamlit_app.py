import streamlit as st
X.append(extract_features(f))
y.append("Bear")
for f in dog_files:
X.append(extract_features(f))
y.append("Dog")
for f in cat_files:
X.append(extract_features(f))
y.append("Cat")
for f in elephant_files:
X.append(extract_features(f))
y.append("Elephant")


if len(X) > 0:
X = np.array(X)
y = np.array(y)


model = make_pipeline(StandardScaler(), SVC(probability=True))
model.fit(X, y)


st.session_state["model"] = model
st.session_state["labels"] = list(set(y))
st.session_state["X_train_size"] = len(X)


preds = model.predict(X)
rep = classification_report(y, preds)
st.session_state["report"] = rep


st.success("ƒê√£ train m√¥ h√¨nh xong!")
st.text(rep)


cm = confusion_matrix(y, preds, labels=st.session_state["labels"])
fig, ax = plt.subplots()
im = ax.imshow(cm, cmap="Blues")
ax.set_xticks(np.arange(len(st.session_state["labels"])))
ax.set_yticks(np.arange(len(st.session_state["labels"])))
ax.set_xticklabels(st.session_state["labels"])
ax.set_yticklabels(st.session_state["labels"])
plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")


for i in range(len(st.session_state["labels"])):
for j in range(len(st.session_state["labels"])):
ax.text(j, i, cm[i, j], ha="center", va="center", color="red")


ax.set_title("Confusion Matrix")
st.pyplot(fig)


# T·∫£i m√¥ h√¨nh
buf = io.BytesIO()
joblib.dump(model, buf)
buf.seek(0)
st.download_button(
label="üíæ T·∫£i v·ªÅ m√¥ h√¨nh",
data=buf,
file_name="animal_sound_classifier.joblib",
mime="application/octet-stream",
)
else:
st.warning("H√£y upload √≠t nh·∫•t 1 file ƒë·ªÉ train.")


# Classification
if classify_clicked:
if "model" not in st.session_state:
st.error("Ch∆∞a c√≥ m√¥ h√¨nh, h√£y train tr∆∞·ªõc.")
else:
feats = extract_features(classify_file)
pred = st.session_state["model"].predict([feats])[0]
proba = st.session_state["model"].predict_proba([feats])[0]
st.success(f"√Çm thanh ƒë∆∞·ª£c ph√¢n lo·∫°i l√†: **{pred}**")
for label, p in zip(st.session_state["model"].classes_, proba):
st.write(f"{label}: {p:.2f}")


# ---------- Export model info ----------
if export_clicked:
if "model" not in st.session_state:
st.error("Ch∆∞a c√≥ m√¥ h√¨nh ƒë·ªÉ xu·∫•t.")
else:
model = st.session_state["model"]
labels = st.session_state.get("labels", [])
n_train = st.session_state.get("X_train_size", 0)
rep = st.session_state.get("report", "(ch∆∞a c√≥)")


st.subheader("üì§ Th√¥ng tin m√¥ h√¨nh")
st.write(f"S·ªë m·∫´u train: **{n_train}**")
st.write(f"Nh√£n: {labels}")
st.code(rep, language="text")


buf = io.BytesIO()
joblib.dump(model, buf)
buf.seek(0)
st.download_button(
label="üíæ T·∫£i v·ªÅ m√¥ h√¨nh (.joblib)",
data=buf,
file_name="animal_sound_classifier.joblib",
mime="application/octet-stream",
)
